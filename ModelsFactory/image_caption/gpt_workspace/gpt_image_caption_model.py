import os
import base64
from abc import abstractmethod
from typing import List, Dict, Union
from enum import Enum

import cv2
import numpy as np
from openai import OpenAI
from openai.types.chat.chat_completion import ChatCompletion

from ModelsFactory.base_model import BaseModel

class DetailLevel(Enum):
    LOW = "low"
    HIGH = "high"
    AUTO = "auto"

class GptImageCaption(BaseModel):
    """
    GptImageCaption extends BaseModel for image captioning using OpenAI's Vision API.
    """

    def __init__(self, prompt: str = None, api_key: str = None):
        super().__init__(prompt)
        self.image = None
        self.prompt = prompt
        self.api_key = api_key

    def init_model(self):
        """
        Initialize the GPT image captioning client.
        """
        if not self.api_key:
            raise ValueError("API key must be provided for initialization.")
        self.client = OpenAI(api_key=self.api_key)

    def set_prompt(self, prompt: str):
        """
        Set the text prompt for image captioning.

        Args:
            prompt (str): The textual description or query for the image.
        """
        self.prompt = prompt

    def encode_image(self, image_path: str) -> str:
        """
        Encode an image file to a base64 string.

        Args:
            image_path (str): Path to the image file.

        Returns:
            str: Base64 encoded string of the image.
        """
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode("utf-8")

    def set_image(self, image: Union[str, np.ndarray]):
        """
        Set the image for captioning. Can be a file path or a NumPy array.

        Args:
            image (Union[str, np.ndarray]): Path to the image file or image as a NumPy array.
        """
        if isinstance(image, str):
            if not os.path.exists(image):
                raise ValueError(f"Image file not found at path: {image}")
            self.image = self.encode_image(image)
        elif isinstance(image, np.ndarray):
            temp_path = "temp_image.png"
            cv2.imwrite(temp_path, image)
            self.image = self.encode_image(temp_path)
        else:
            raise ValueError("Invalid image type. Provide a file path or a NumPy array.")

    def get_result(self) -> str:
        """
        Perform image captioning using the OpenAI API.

        Returns:
            str: The textual description generated by the model.
        """
        if not self.image:
            raise ValueError("Image not set. Please use set_image to provide an image.")

        if not self.prompt:
            raise ValueError("Prompt not set. Please use set_prompt to provide a prompt.")

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": self.prompt},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/png;base64,{self.image}"},
                            },
                        ],
                    }
                ],
                max_tokens=300,
            )
            return response.choices[0].message.content

        except Exception as e:
            raise RuntimeError(f"Error during image captioning: {str(e)}")

    def save_result(self, output_directory: str, save_image: bool = True):
        """
        Save the captioning result and optionally the original image to a specified directory.

        Args:
            output_directory (str): Path to the directory to save the result.
            save_image (bool): Flag indicating whether to save the original image. Defaults to True.
        """
        if not self.image:
            raise ValueError("Image not set. Please use set_image to provide an image.")

        result = self.get_result()
        os.makedirs(output_directory, exist_ok=True)

        # Save the caption text
        caption_file_path = os.path.join(output_directory, "caption.txt")
        with open(caption_file_path, "w") as output_file:
            output_file.write(result)
        print(f"Captioning result saved to {caption_file_path}")

        # Save the original image if the flag is True
        if save_image:
            image_file_path = os.path.join(output_directory, "original_image.png")
            with open(image_file_path, "wb") as image_file:
                image_file.write(base64.b64decode(self.image))
            print(f"Original image saved to {image_file_path}")

    def set_prompt_does_is(self, object_name: str, threshold: float = 0.30) -> bool:
        """
        Determine if the object is present in the image above a certain threshold.

        Args:
            object_name (str): The object to check for.
            threshold (float): The confidence threshold.

        Returns:
            bool: True if the object is likely present, False otherwise.
        """
        prompt = (
            f"Does the image contain {object_name}? Please respond in the following format: "
            f"Yes or No, and then the confidence value (e.g., 'Yes, 0.9' or 'No, 0.2')."
        )
        self.set_prompt(prompt)
        result = self.get_result()

        try:
            # Parse the response to extract Yes/No and confidence
            answer, confidence = result.split(",")
            confidence = float(confidence.strip())
            return answer.strip().lower() == "yes" and confidence >= threshold
        except (ValueError, IndexError):
            raise RuntimeError("Unable to parse the response. Ensure the response is in the correct format.")

    def set_prompt_describe_image(self, detail: DetailLevel=DetailLevel.AUTO) -> str:
        """
        Describe the image with the specified level of detail.

        Args:
            detail (DetailLevel): The level of detail (low, high, auto).

        Returns:
            str: The image description.
        """
        prompt = f"Please describe the image in {detail.value} detail."
        self.set_prompt(prompt)
        return self.get_result()

    def set_prompt_get_all_classes_from_image(self, also_like_to_be: bool = True, add_synonym: bool = False) -> List[
        str]:
        """
        Ask the GPT to provide all objects it detects in the image, optionally including synonyms.

        Args:
            also_like_to_be (bool): If True, also include objects the model thinks might be in the image.
            add_synonym (bool): If True, include synonyms for detected objects.

        Returns:
            List[str]: A list of object names (and synonyms if requested) detected in the image.
        """
        prompt = (
            "List all objects and sub objects you see or think in the image, list the word in singular and not the plural literally everything. try hard"
            "in format object_name1,object_name2,object_name3 without nothing else. "
            "If there is a chance that certain objects might be in the image, include them as well, "
            "but only if they have a reasonable likelihood of being present. "
            if also_like_to_be else
            "List all objects you clearly see in the image. "
        )

        if add_synonym:
            prompt += "For each object, also include synonyms words."

        self.set_prompt(prompt)
        result = self.get_result()

        try:
            # Split the result into a list of object names and synonyms
            object_names = [obj.strip() for obj in result.split(",") if obj.strip()]
            return object_names
        except Exception:
            raise RuntimeError("Unable to parse the response. Ensure the response is in the correct format.")

    def set_prompt_most_match_description(self, list_of_optional_description: List[str]) -> Dict[str, str]:
        """
        Find the most matching description from a list of options.

        Args:
            list_of_optional_description (List[str]): List of descriptions to match.

        Returns:
            Dict[str, str]: The zero-based index and text of the best matching description.
        """
        prompt = (
                "Which of the following descriptions best matches the image? "
                "Please respond only with the number index and with nothing else.\n" +
                "\n".join([f"{i + 1}. {desc}" for i, desc in enumerate(list_of_optional_description)])
        )
        self.set_prompt(prompt)
        result = self.get_result()

        try:
            index = int(result.strip()) - 1  # Convert to zero-based index
            if 0 <= index < len(list_of_optional_description):
                return {"index": index, "description": list_of_optional_description[index]}
            else:
                raise ValueError("Index out of range.")
        except (ValueError, IndexError):
            raise RuntimeError("Unable to parse the result or match the description.")

    def set_prompt_most_match_object(self, list_of_optional_object: List[str]) -> Dict[str, str]:
        """
        Find the most matching object name from a list of options.

        Args:
            list_of_optional_object (List[str]): List of object names to match.

        Returns:
            Dict[str, str]: The zero-based index and name of the best matching object.
        """
        prompt = (
                "Which of the following objects is most present in the image? "
                "Please respond only with the number index. and with nothing else.\n" +
                "\n".join([f"{i + 1}. {obj}" for i, obj in enumerate(list_of_optional_object)])
        )
        self.set_prompt(prompt)
        result = self.get_result()

        try:
            index = int(result.strip()) - 1  # Convert to zero-based index
            if 0 <= index < len(list_of_optional_object):
                return {"index": index, "object": list_of_optional_object[index]}
            else:
                raise ValueError("Index out of range.")
        except (ValueError, IndexError):
            raise RuntimeError("Unable to parse the result or match the object.")


# Example Usage
if __name__ == "__main__":
    model = GptImageCaption()
    model.init_model()
    # model.set_image("/home/nehoray/PycharmProjects/UniversaLabeler/data/tested_image/Soi/WhatsApp Image 2024-12-29 at 13.15.14.jpeg")

    # model.set_prompt("What's in this image?")
    # result = model.get_result()

    # most_macth_object = model.set_prompt_most_match_object(["bus", "person", "building"])

    # most_match_description = model.set_prompt_most_match_description(["a building","a car","a box"])

    # det = model.set_prompt_describe_image(DetailLevel.HIGH)
    # model.set_image("/home/nehoray/PycharmProjets/UniversaLabeler/data/tested_image/segmentation/sam_eample_tiny.png")
    # does_it = model.set_prompt_does_is("car")

    # model.set_image("/home/nehoray/PycharmProjects/UniversaLabeler/data/tested_image/detection/from_sky.jpeg")
    model.set_image("/home/nehoray/PycharmProjects/UniversaLabeler/data/tested_image/detection/from_sky.jpeg")
    model.set_image("/home/nehoray/PycharmProjects/UniversaLabeler/data/tested_image/detection/street.png")

    res = model.set_prompt_get_all_classes_from_image()
    all_objects = model.set_prompt_get_all_classes_from_image(add_synonym=True)
    # model.save_result("path/to/output", save_image=True)
